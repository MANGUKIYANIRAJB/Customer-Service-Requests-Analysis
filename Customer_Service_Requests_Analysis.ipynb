{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd51d432",
   "metadata": {},
   "source": [
    "# <u>Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b712c4",
   "metadata": {},
   "source": [
    "# 1. Importing the Dataset and doing Data Preprocessing on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fabc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46743f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "# Note: Our Dataset is very large so setting low_memory to false\n",
    "dataset = pd.read_csv('Service_Requests_from_2010_to_Present.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7df91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the top 5 elements of the dataset\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1476df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adfc7b",
   "metadata": {},
   "source": [
    "#### There are a lot of columns in our dataset but I don't need all of them. So I will drop the columns that have a very large number of null values in it. Also I don't need the unnecessary columns, so I will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e61217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the columns\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86df64",
   "metadata": {},
   "source": [
    "- Columns with most of its values as null are dropped\n",
    "- Agency and Agency Name are more or less same, so I am dropping Agency Name\n",
    "- Dropping other unnecessary columns like Location, Incident Adrress, Street Name, X Coordinate (State Plane), Y Coordinate (State Plane)  as we are already considering LATITUDE and LONGITUDE\n",
    "- Dropping other unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the irrelevant columns\n",
    "drop_columns = ['Agency Name','Incident Address','Street Name','Cross Street 1','Cross Street 2','Intersection Street 1',\n",
    "'Intersection Street 2','Address Type','Park Facility Name','Park Borough','School Name',\n",
    "'School Number','School Region','School Code','School Phone Number','School Address','School City',\n",
    "'School State','School Zip','School Not Found','School or Citywide Complaint','Vehicle Type',\n",
    "'Taxi Company Borough','Taxi Pick Up Location','Bridge Highway Name','Bridge Highway Direction',\n",
    "'Road Ramp','Bridge Highway Segment','Garage Lot Name','Ferry Direction','Ferry Terminal Name','Landmark',\n",
    "'X Coordinate (State Plane)','Y Coordinate (State Plane)','Due Date','Resolution Action Updated Date','Community Board','Facility Type',\n",
    "'Location']\n",
    "\n",
    "dataset = dataset.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9596e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of our dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd44327",
   "metadata": {},
   "source": [
    "#### So we are upto 14 columns from 53...That's a lot of reduction !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd27d7f",
   "metadata": {},
   "source": [
    "- ### Now check for null values, data type of the columns etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6fb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the info of the dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of null values in the columns\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the closed cases only to eliminate the null values\n",
    "\n",
    "dataset = dataset[dataset['Status'] == 'Closed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96abeb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since all the cases are of closed cases we can now drop the column Status as every value of its data are same\n",
    "dataset = dataset.drop(['Status'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of the remaining columns only Descriptor, Latitude and Longitude has over 1k null values\n",
    "dataset = dataset[(dataset['Descriptor'].notnull()) & (dataset['Latitude'].notnull()) &(dataset['Longitude'].notnull())]\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b959bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rechecking remaining null values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# still there are few null values in our dataset. we will remove them\n",
    "dataset = dataset[(dataset['Location Type'].notnull()) & (dataset['Incident Zip'].notnull()) &(dataset['City'].notnull())]\n",
    "\n",
    "# rechecking for null values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2a885",
   "metadata": {},
   "source": [
    "-- So all Null values are removed from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61416d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape our datset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88255558",
   "metadata": {},
   "source": [
    "**2. Read or convert the columns â€˜Created Dateâ€™ and Closed Dateâ€™ to datetime datatype and create a new column â€˜Request_Closing_Timeâ€™ as the time elapsed between request creation and request closing. (Hint: Explore the package/module datetime)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 'Created Date' and 'Closed Date' to datetime datatype\n",
    "\n",
    "cols = ['Created Date', 'Closed Date']\n",
    "for col in cols:\n",
    "    dataset[col] = pd.to_datetime(dataset[col],infer_datetime_format=True)\n",
    "    \n",
    "# creating a new column Request_Closing_Time\n",
    "dataset['Request_Closing_Time'] = dataset[cols[1]] - dataset[cols[0]]\n",
    "\n",
    "# viewing the info to see the data types\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3894417",
   "metadata": {},
   "source": [
    "**3. Provide major insights/patterns that you can offer in a visual format (graphs or tables); at least 4 major conclusions that you can come up with after generic data mining.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying describe on the dataset\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the columns\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f49bab",
   "metadata": {},
   "source": [
    "### We will analyse Agency, Complaint Type, Descriptor, Location Type, City, Borough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8919aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the complaints are under the same agency\n",
    "dataset['Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e077f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complaint types\n",
    "dataset['Complaint Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the complaint types\n",
    "dataset['Complaint Type'].value_counts().plot(kind = 'bar', figsize=(15, 7), title='Complaint Types', ylabel='Count', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5693f97",
   "metadata": {},
   "source": [
    "- so <b>Blocked Driveway</b> is the Maximum Complaint type followed by Illegal Parking, Noise-Street/Sidewalk, Noise-Commercial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptors\n",
    "dataset['Descriptor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting top 10 Descriptors\n",
    "dataset['Descriptor'].value_counts().head(10).plot(kind='barh', grid=True, figsize=(10,5), title='Top 10 Descriptors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a1156",
   "metadata": {},
   "source": [
    "- So <b>Loud Music/Party</b> is the <u>maximum</u> descriptor for the complaints followed by No Access, Posted Parking Sign Violation and Loud Taking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Location Type\n",
    "dataset['Location Type'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2665f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Top 10 Location Type\n",
    "dataset['Location Type'].value_counts().head(10).plot(kind='barh', grid=True, figsize=(10, 5), title='Top 10 Location Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313676a",
   "metadata": {},
   "source": [
    "- So we see that the Location Type of <b>Street/Sidewalk</b> is a lot more than any other members of its category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0797770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City\n",
    "dataset['City'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the cities\n",
    "dataset['City'].value_counts().head(10).plot(kind='barh', grid=True, figsize=(10, 5), title='City Column', ylabel='Cities')\n",
    "plt.xlabel('Complaint Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81a3c2",
   "metadata": {},
   "source": [
    "- So most complaints are from <b>BROOKLYN</b> followed New York, Bronx, Staten Island in City wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a699452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borough\n",
    "dataset['Borough'].value_counts().head(10).plot(kind='barh', grid=True, figsize=(10, 5), title='Borough Column', ylabel='Borough')\n",
    "plt.xlabel('Complaint Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46f803",
   "metadata": {},
   "source": [
    "### Till now we only analyse one column. Lets analyse Borough and Complaint Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03406904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Complaints\n",
    "top_6_complaints = dataset['Complaint Type'].value_counts()[:6].keys()\n",
    "top_6_complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60aed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borough per Complaints\n",
    "borough_complaints = dataset.groupby(['Borough', 'Complaint Type']).size().unstack()\n",
    "borough_complaints = borough_complaints[top_6_complaints]\n",
    "borough_complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Borough per Complaint Type \n",
    "col_number = 2\n",
    "row_number = 3\n",
    "fig, axes = plt.subplots(row_number,col_number, figsize=(12,8))\n",
    "\n",
    "for i, (label,col) in enumerate(borough_complaints.items()):\n",
    "    ax = axes[int(i/col_number), i%col_number]\n",
    "    col = col.sort_values(ascending=True)[:15]\n",
    "    col.plot(kind='barh', ax=ax, grid=True)\n",
    "    ax.set_title(label)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd5f41",
   "metadata": {},
   "source": [
    "<u>ANALYSIS:</u>\n",
    "    \n",
    "    - Blocked Driveway is maximum in QUEENS\n",
    "    - Illegal Parking is maximum in BROOKLYN\n",
    "    - Noise - Street/Sidewalk is maximum in MANHATTAN\n",
    "    - Noise - Commercial is maximum in MANHATTAN\n",
    "    - Derelict Vehicle is maximum in QUEENS\n",
    "    - Noise - Vehicle is maximum in QUEENS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556ebc4",
   "metadata": {},
   "source": [
    "- Similarly for Complaints per Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly for Complaints per Borough\n",
    "top_borough = dataset['Borough'].value_counts().keys()\n",
    "\n",
    "complaint_per_borough = dataset.groupby(['Complaint Type', 'Borough']).size().unstack()\n",
    "complaint_per_borough = complaint_per_borough[top_borough]\n",
    "complaint_per_borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Complaints per Borough\n",
    "col_number = 2\n",
    "row_number = 3\n",
    "fig, axes = plt.subplots(row_number,col_number, figsize=(12,10))\n",
    "\n",
    "for i, (label,col) in enumerate(complaint_per_borough.items()):\n",
    "    ax = axes[int(i/col_number), i%col_number]\n",
    "    col = col.sort_values(ascending=True)[:15]\n",
    "    col.plot(kind='barh', ax=ax, grid=True)\n",
    "    ax.set_title(label)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf939fc6",
   "metadata": {},
   "source": [
    "<u>ANALYSIS:</u>\n",
    "\n",
    "    - BROOKLYN, QUEENS and BRONX has most complaints of Blocked Driveway.\n",
    "    - MANHATTAN has most complaints of Noise - Street/Sidewalk.\n",
    "    - STATEN ISLAND has most complaints of Illegal Parking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8c422",
   "metadata": {},
   "source": [
    "**4. Order the complaint types based on the average â€˜Request_Closing_Timeâ€™, grouping them for different locations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column Request_Closing_Time_in_Hours for time in Hours\n",
    "# and we will say the said complaint has been closed under x hours\n",
    "dataset['Request_Closing_Time_in_Hours'] = dataset['Request_Closing_Time'].dt.total_seconds() / 3600 + 1\n",
    "\n",
    "# viewing the Two columns side by side for first 20 entries\n",
    "dataset[['Request_Closing_Time', 'Request_Closing_Time_in_Hours']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45799e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ordering the complaint types based on the average â€˜Request_Closing_Timeâ€™ in Hours, grouping them for different locations.\n",
    "data_avg_time_in_hrs = dataset.groupby(['City', 'Complaint Type'])['Request_Closing_Time_in_Hours'].mean()\n",
    "data_avg_time_in_hrs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column Request_Closing_Time_in_Seconds for time in seconds\n",
    "dataset['Request_Closing_Time_in_Seconds'] = dataset['Request_Closing_Time'].astype('timedelta64[s]')\n",
    "\n",
    "# viewing the Three columns side by side\n",
    "dataset[['Request_Closing_Time', 'Request_Closing_Time_in_Hours','Request_Closing_Time_in_Seconds']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Order the complaint types based on the average â€˜Request_Closing_Timeâ€™ in seconds, grouping them for different locations.\n",
    "data_avg_in_seconds = dataset.groupby(['City', 'Complaint Type']).Request_Closing_Time_in_Seconds.mean()\n",
    "data_avg_in_seconds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539cfdd",
   "metadata": {},
   "source": [
    "- <u>Other analysis works on Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e17a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets analyse the Request_Closing_Time\n",
    "dataset['Request_Closing_Time'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec573f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32b53afb",
   "metadata": {},
   "source": [
    "### We will now analyse Complaint Types column on the basis of <u>Months</u> by refering to <u>Created Date</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfdaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for analysing on the basis of month we will need to separate months from Created Date column\n",
    "dataset['Year-Month'] = dataset['Created Date'].apply(lambda x:datetime.datetime.strftime(x, '%Y-%m'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8dc8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the months that we have in our dataset\n",
    "dataset['Year-Month'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e807f0",
   "metadata": {},
   "source": [
    "- Looks like we have incident complaints from <b>March</b> to <b>December</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the month column\n",
    "#dataset['Year-Month'].value_counts().plot()\n",
    "monthly_incidents =  dataset.groupby('Year-Month').size().plot(figsize=(12,5),\n",
    "                                                               title='Incident Counts on a monthly basis', ylabel='Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa477f98",
   "metadata": {},
   "source": [
    "- Are <b>January</b> and <b>Ferbruary</b> does not have any Complaints? Looks like nobody wants to go out in cold weather....ðŸ˜‰\n",
    "- We don't have any complaints from <b>January</b> and <b>Ferbruary</b> in our dataset because we might have eliminated them as <b>Null Values</b> earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Borough on the basis of Year-Month\n",
    "dataset.groupby(['Year-Month','Borough']).size().unstack().plot(figsize=(15,7))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c190fb5a",
   "metadata": {},
   "source": [
    "- <b>BROOKLYN</b> raised most cases all over and most of them were raised in <b>MAY-JUNE</b> and <b>SEPTEMBER</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c87e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Year-Month on the basis of Borough\n",
    "dataset.groupby(['Borough', 'Year-Month']).size().unstack().plot(figsize=(15,7))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0b947",
   "metadata": {},
   "source": [
    "- <b>DECEMBER</b> has raised least complaints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing time per Borough on a monthly basis\n",
    "dataset.groupby(['Year-Month','Borough'])['Request_Closing_Time_in_Hours'].mean().unstack().plot(figsize=(15,7),\n",
    "                                                                        title='Processing time per Borough on a monthly basis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26be4840",
   "metadata": {},
   "source": [
    "- <b>BRONX</b> has the maximum Processing time every month even though it has the least complaints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eecbc4",
   "metadata": {},
   "source": [
    "# 5. Perform a statistical test for the following:\n",
    "**Please note: For the below statements you need to state the Null and Alternate and then provide a statistical test to accept or reject the Null Hypothesis along with the corresponding â€˜p-valueâ€™.**\n",
    "\n",
    "\n",
    "## a. Whether the average response time across complaint types is similar or not (overall)\n",
    "## b. Are the type of complaint or service requested and location related?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc70788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the columns\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1050b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see the average response time in seconds for different complaint types\n",
    "avg_response_time = dataset.groupby(['Complaint Type']).Request_Closing_Time_in_Seconds.mean().sort_values(ascending=True)\n",
    "avg_response_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2c69b",
   "metadata": {},
   "source": [
    "- <b>Null Hypothesis</b> -->>  Average response time across complaint types is similar(overall).\n",
    "- <b>Alternate Hypothesis</b> -->> Average response time across complaint types is not similar(overall).\n",
    "\n",
    "-- We can say that for overall case our <b>NULL HYPOTHESIS</b> is rejected as the Average Response Time in Seconds for different complaint types is different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a0554",
   "metadata": {},
   "source": [
    "# Testing for our Hypothesis\n",
    "\n",
    "- Below We conduct ANOVA (Analysis of Variance) test for top 5 type of complaints\n",
    "\n",
    "- For a 95% of confidence interval we choose our alpha as 0.05 for 5%\n",
    "\n",
    "- Alpha(0.05) is the critical p-value, if our calculated p-value is less than alpha, it will give us strong evidence to reject Null Hypothesis.\n",
    ">\n",
    "- <b>if p < alpha(0.05) <b>: Reject Null Hypothesis, Average response time for all the complaints type is not same.</b>\n",
    "\n",
    "- <b>if p > alpha(0.05) : Fail to reject Null Hypothesis, Average response time for all the complaints type is same.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the p-value log of time taken to close the complaint per complaint is taken\n",
    "#data = {}\n",
    "#for complaint in dataset['Complaint Type'].unique():\n",
    " #   data[complaint] = np.log(dataset[dataset['Complaint Type']==complaint]['Request_Closing_Time_in_Seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccccd4-9129-4147-ae2c-495426d4bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# Iterate over unique complaint types\n",
    "for complaint in dataset['Complaint Type'].unique():\n",
    "    # Filter dataset to rows where 'Complaint Type' matches 'complaint'\n",
    "    filtered_data = dataset[dataset['Complaint Type'] == complaint]\n",
    "    \n",
    "    # Filter out rows with non-numeric or invalid values in 'Request_Closing_Time_in_Seconds'\n",
    "    valid_data = filtered_data.dropna(subset=['Request_Closing_Time_in_Seconds'])\n",
    "    \n",
    "    # Apply np.log() only to valid numeric values\n",
    "    if not valid_data.empty:\n",
    "        valid_data['Request_Closing_Time_in_Seconds'] = valid_data['Request_Closing_Time_in_Seconds'].astype(float)\n",
    "        data[complaint] = np.log(valid_data['Request_Closing_Time_in_Seconds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b374022",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696bdafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for complaint in data.keys():\n",
    "    print(data[complaint].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3be236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing f_oneway from scipy.stats library\n",
    "from scipy.stats import f_oneway\n",
    "# taking top 5 complaints\n",
    "stat, p = f_oneway(data['Blocked Driveway'], data['Illegal Parking'], data['Noise - Street/Sidewalk'],\n",
    "                   data['Derelict Vehicle'], data['Noise - Commercial'])\n",
    "print('Statistics= %.3f, p = %.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('We have Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e8210",
   "metadata": {},
   "source": [
    "- <b>As our p-value is quite low , hence it is being converted to 0.0</b>\n",
    "\n",
    "- Since our p-value is lower than our critical p-value, we will conclude that we have enough evidence to reject our Null Hypothesis and that is:\n",
    "\n",
    "- Average response time for all the complaints type is not same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecd78e",
   "metadata": {},
   "source": [
    "### For relation between Complaint Type and Location\n",
    "we will use Crosstab and Chi-square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6466d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting crosstab from pandas\n",
    "city_type = pd.crosstab(dataset['City'], dataset['Complaint Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c93968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing first 5 entries of city_type\n",
    "city_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do Chi-square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contigency table\n",
    "table = city_type \n",
    "# table -->> The contingency table. The table contains the observed frequencies (i.e. number of occurrences) in each category.\n",
    "# stat -->> chi2 or Test Statistic\n",
    "# p -->> The p-value of the Test\n",
    "# dof -->> Degrees of Freedom\n",
    "# expected -->> The expected frequencies, based on the marginal sums of the table.\n",
    "stat, p, dof, expected = chi2_contingency(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850123e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Degrees of Freedom are : {}'. format(dof))\n",
    "print('The P-Value of the Testing is {}: '.format(p))\n",
    "print('Expected values : \\n')\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreting test statistics\n",
    "prob = 0.95 # as aplha is considered 0.05\n",
    "critical_value = chi2.ppf(prob, dof)\n",
    "critical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9672b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability = {}, Critical Value = {}, Test statistic = {}'.format(prob, critical_value, stat))\n",
    "print()\n",
    "if abs(stat) >= critical_value:\n",
    "    print('Dependent (Reject H0 or Null Hypothesis)')\n",
    "else:\n",
    "    print('Independent (Failed to reject Null Hypothesis)')\n",
    "\n",
    "\n",
    "# interpreting the P-Value\n",
    "alpha = 1 - prob\n",
    "print('Significance : %.3f, P-Value : %.2f'%(alpha, p))\n",
    "if p <= alpha:\n",
    "    print('Dependent (Reject H0 or Null Hypothesis)')\n",
    "else:\n",
    "    print('Independent (Failed to reject Null Hypothesis)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
